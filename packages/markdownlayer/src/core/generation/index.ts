import { camelCase } from 'change-case';
import chokidar, { type FSWatcher } from 'chokidar';
import fs from 'fs';
import GithubSlugger from 'github-slugger';
import { globby } from 'globby';
import matter from 'gray-matter';
import { pluralize } from 'inflection';
import beautify from 'js-beautify';
import type { StaticImageData } from 'next/dist/shared/lib/image-external';
import path from 'path';
import readingTime from 'reading-time';
import type { PackageJson } from 'type-fest';
import { z, type ZodSchema } from 'zod';
import { printNode, zodToTs } from 'zod-to-ts';

import type { BaseDoc, GenerationMode, TocItem } from '@/core/types';
import { version } from '../../../package.json';
import { MarkdownlayerError, MarkdownlayerErrorData, errorMap, getYAMLErrorLine } from '../errors';
import { getFileLastUpdate, type LastUpdateData } from '../git';
import type {
  DocumentDefinition,
  DocumentDefinitionSchema,
  DocumentMeta,
  MarkdownlayerConfig,
  MarkdownlayerConfigPlugins,
} from '../types';
import { bundle, type BundleProps } from './bundle';
import { getConfig } from './config-file';
import type { DataCache } from './data-cache';
import { getFormat } from './format';

type GeneratedCount = { cached: number; generated: number; total: number };

const autogeneratedNote = `// NOTE This file is auto-generated on build.`;

let configWatcher: FSWatcher | null;
let contentWatcher: FSWatcher | null;

export type GenerateOptions = {
  /**
   * Build mode.
   * Enables production optimizations or development hints.
   */
  mode: GenerationMode;

  /** Current working directory. */
  cwd?: string;

  /** Plugin configuration. */
  pluginConfig?: MarkdownlayerConfig;
};

export async function generate(options: GenerateOptions) {
  const { mode, cwd = process.cwd(), pluginConfig } = options;

  // close the config watcher if it exists
  if (configWatcher) {
    configWatcher.close();
    configWatcher = null;
  }

  // get the config (provided in the plugin or compiled from the config file)
  const outputFolder = path.join(cwd, '.markdownlayer');
  const { configPath, configHash, config } = await getConfig({ cwd, outputFolder, pluginConfig });

  // generate the content (initial)
  await generateInner({ mode, cwd, outputFolder, config, configHash });

  // watch for config changes in the content folder (development mode only)
  if (mode === 'development' && configPath) {
    const fileName = path.basename(configPath);
    const currentConfigPath = configPath;
    configWatcher = chokidar.watch(configPath, { ignoreInitial: true });
    configWatcher.on('all', async (eventName) => {
      if (eventName === 'add') console.log(`${fileName} added`);
      else if (eventName === 'change') console.log(`${fileName} changed`);
      else if (eventName === 'unlink') {
        console.log(`${fileName} deleted. This requires a restart of the server.`);
        return;
      } else return;

      // get the new config and regenerate the content
      const { configHash, config } = await getConfig({ cwd, outputFolder, pluginConfig, currentConfigPath });
      await generateInner({ mode, cwd, outputFolder, config, configHash });
    });
  }
}

type GenerateInnerOptions = Pick<GenerateOptions, 'mode'> & {
  cwd: string;
  outputFolder: string;
  config: MarkdownlayerConfig;
  configHash: string;
};

export async function generateInnerWatchIfNecessary(options: GenerateInnerOptions) {
  const { mode, cwd = process.cwd(), outputFolder, config, configHash } = options;

  // close the content watcher if it exists
  if (contentWatcher) {
    contentWatcher.close();
    contentWatcher = null;
  }

  // generate the documents (initial)
  await generateInner({ mode, cwd, outputFolder, config, configHash });

  // watch for content changes in the content folder (development mode only)
  if (mode === 'development') {
    contentWatcher = chokidar.watch(config.contentDirPath, { ignoreInitial: true });
    contentWatcher.on('all', async (eventName, path) => {
      if (eventName === 'add') console.log(`File added: ${path}`);
      else if (eventName === 'change') console.log(`File changed: ${path}`);
      else if (eventName === 'unlink') console.log(`File deleted: ${path}`);
      else return;

      await generateInner({ mode, cwd, outputFolder, config, configHash });
    });
  }
}

async function generateInner(options: GenerateInnerOptions) {
  const {
    mode,
    cwd,
    configHash,
    config: { caching = true, contentDirPath, definitions, mdAsMarkdoc = false, ...plugins },
  } = options;
  let outputFolder = options.outputFolder;

  // ensure there are no definitions with duplicate types
  const types = definitions.map((def) => def.type);
  const uniqueTypes = new Set(types);
  if (types.length !== uniqueTypes.size) {
    const duplicates = types.filter((type, index) => types.indexOf(type) !== index);
    throw new MarkdownlayerError({
      ...MarkdownlayerErrorData.DuplicateDefinitionNameError,
      message: MarkdownlayerErrorData.DuplicateDefinitionNameError.message({ names: duplicates }),
    });
  }

  // ensure that all definitions have at least one pattern
  const definitionsWithNoPatterns = definitions.filter((def) => def.patterns.length === 0);
  if (definitionsWithNoPatterns.length > 0) {
    const types = definitionsWithNoPatterns.map((def) => def.type);
    throw new MarkdownlayerError({
      ...MarkdownlayerErrorData.DefinitionsWithNoPatternsError,
      message: MarkdownlayerErrorData.DefinitionsWithNoPatternsError.message({ names: types }),
    });
  }

  // load cache from file if it exists, otherwise create a new cache
  // changes in configuration options and plugins will invalidate the cache
  const cacheFilePath = path.join(outputFolder, `cache/v${version}/data-${configHash}.json`);
  let cache: DataCache = { items: {} };
  if (caching && fs.existsSync(cacheFilePath)) {
    cache = JSON.parse(fs.readFileSync(cacheFilePath, 'utf8'));
  }

  // write package.json
  fs.mkdirSync(outputFolder, { recursive: true });
  await writePackageJson({ outputFolder, configHash });

  // iterate over the definitions and generate the docs
  outputFolder = path.join(outputFolder, 'generated');
  const contentDir = path.join(cwd, contentDirPath);
  const generations: Record<string, GenerationResult> = {};
  for (const def of definitions) {
    const generation = await generateDocuments({ ...def, mode, contentDir, outputFolder, mdAsMarkdoc, plugins, cache });
    generations[def.type] = generation;
  }

  // write cache to file
  cache.elapsed = Object.values(cache.items).reduce((acc, item) => acc + item.elapsed, 0);
  fs.mkdirSync(path.dirname(cacheFilePath), { recursive: true });
  fs.writeFileSync(cacheFilePath, JSON.stringify(cache, null, 2), { encoding: 'utf8' });

  // write files that would be imported by the application (index.d.ts, index.mjs)
  await writeRootIndexFiles({ outputFolder, generations });

  // print some stats
  const { cached, total }: GeneratedCount = Object.values(generations)
    .map((g) => g.counts)
    .reduce((acc, count) => {
      acc.cached += count.cached;
      acc.generated += count.generated;
      acc.total += count.total;
      return acc;
    });
  console.log(`Generated ${total} documents (${cached} from cache) in .markdownlayer`);
}

type GenerateDocsOptions = DocumentDefinition & {
  mode: GenerationMode;
  contentDir: string;
  ignoreFiles?: string | readonly string[];
  outputFolder: string;
  mdAsMarkdoc: boolean;
  plugins: MarkdownlayerConfigPlugins;
  cache: DataCache;
};

type GenerationResult = { schema?: DocumentDefinitionSchema; counts: GeneratedCount };
async function generateDocuments(options: GenerateDocsOptions): Promise<GenerationResult> {
  const {
    mode,
    type,
    format = 'detect',
    contentDir,
    patterns,
    lastUpdatedFromGit = true,
    authorFromGit = false,
    toc: genToc = false,
    validate,
    ignoreFiles,
    outputFolder,
    mdAsMarkdoc,
    plugins,
    cache,
  } = options;

  // find the files
  const files = await globby(patterns, { cwd: contentDir, ignoreFiles: ignoreFiles, gitignore: true });

  let cached = 0;
  let generated = 0;
  const docs: BaseDoc[] = [];
  let collectionChanged = false;

  fs.mkdirSync(path.join(outputFolder, type), { recursive: true });

  let schema = options.schema;
  if (typeof schema === 'function') {
    schema = schema({
      // TODO: figure out how to handle images in the schema without needing to pass the file path (module augmentation may help)
      image: (optional) =>
        // @ts-expect-error - The type is correct but the error is due to the transform function
        (optional ? z.string().optional() : z.string()).transform(
          (): StaticImageData => ({ src: '', height: 0, width: 0 }),
        ),
      // image: (optional) => createImage({ optional, shouldEmitFile: false, mode, sourceFilePath }),
    });
  }

  // parse the files and "compile" in a loop
  for (const file of files) {
    const sourceFilePath = path.join(contentDir, file);

    // if the file has not been modified, use the cached version
    const hash = fs.statSync(sourceFilePath).mtimeMs.toString();
    const cacheEntry = cache.items[file];
    const changed = !cacheEntry || cacheEntry.hash !== hash;
    if (!changed) {
      docs.push(cacheEntry.document);
      cached++;
      continue;
    }

    // at this point we know that the file has changed and we need to recompile
    // it also means that the collection has changed
    collectionChanged = true;

    const start = performance.now();

    const contents = fs.readFileSync(sourceFilePath, 'utf8');
    const parsedMatter = matter(contents);
    const frontmatter = parsedMatter.data as Record<string, unknown>;

    // determine the document format
    let documentFormat = getFormat({ file, format });
    if (documentFormat === 'md' && mdAsMarkdoc) documentFormat = 'mdoc';

    const bundleOptions: BundleProps = {
      contents,
      entryPath: sourceFilePath,
      format: documentFormat,
      mode,
      plugins,
      frontmatter,
    };
    const { code, errors } = await bundle(bundleOptions);
    if (errors && errors.length) {
      console.error(errors);
      throw new Error('Failed to bundle file: ' + file);
    }

    const end = performance.now();
    const elapsed = end - start;

    //  only pull git info if in production mode
    let lastUpdate: LastUpdateData | null = null;
    if (mode === 'production' && lastUpdatedFromGit) {
      lastUpdate = await getFileLastUpdate(path.join(contentDir, file));
    }

    const meta: DocumentMeta = {
      _id: file,
      _info: {
        sourceFilePath: file,
        sourceFileName: path.basename(file),
        sourceFileDir: path.dirname(file),
        flattenedPath: getFlattenedPath(file),
        frontmatter: frontmatter,
      },

      type: type,
      git: lastUpdate == undefined ? undefined : { date: lastUpdate.date, authors: [lastUpdate.author] },
      format: documentFormat,
      body: { raw: contents, code: code },
      readingTime: readingTime(contents),
    };

    let data: Record<string, unknown> = frontmatter;
    if (schema) {
      // Note: will not work for `z.union` or `z.intersection` schemas
      if (typeof schema === 'object' && 'shape' in schema) {
        // Catch reserved `slug` field inside content schemas
        if (schema.shape.slug) {
          throw new MarkdownlayerError({
            ...MarkdownlayerErrorData.DefinitionSchemaContainsSlugError,
            message: MarkdownlayerErrorData.DefinitionSchemaContainsSlugError.message({ definition: type }),
          });
        }

        // we set updated in the frontmatter if:
        // - it is not already set
        // - it is present in the git metadata
        if (!frontmatter.updated && meta.git?.date) {
          // we set the string and let the schema handle the coercion if necessary
          frontmatter.updated = meta.git.date.toISOString();
        }

        // we set authors/author in the frontmatter if:
        // - it is present in git metadata
        // - authorsFromGit is enabled
        // - it is not already present
        if (meta.git?.authors && authorFromGit) {
          if (!frontmatter.authors) {
            frontmatter.authors = meta.git.authors;
          }

          // first author is the latest
          if (!frontmatter.author && meta.git.authors.length > 0) {
            frontmatter.author = meta.git.authors[0];
          }
        }
      }

      // Use `safeParseAsync` to allow async transforms
      let formattedError;
      const parsed = await (schema as ZodSchema).safeParseAsync(frontmatter, {
        errorMap(error, ctx) {
          if (error.code === 'custom' && error.params?.isHoistedMarkdownlayerError) {
            formattedError = error.params?.markdownlayerError;
          }
          return errorMap(error, ctx);
        },
      });
      if (parsed.success) {
        data = parsed.data as Record<string, unknown>;
      } else {
        if (!formattedError) {
          formattedError = new MarkdownlayerError({
            ...MarkdownlayerErrorData.InvalidDocumentFrontmatterError,
            message: MarkdownlayerErrorData.InvalidDocumentFrontmatterError.message({
              definition: type,
              documentId: meta._id,
              error: parsed.error,
            }),
            location: {
              file: meta._info.sourceFilePath,
              line: getYAMLErrorLine(parsedMatter.matter, String(parsed.error.errors[0].path[0])),
              column: 0,
            },
          });
        }
        throw formattedError;
      }
    }

    // generate table of contents if requested
    const toc = frontmatter.toc ?? genToc ? generateToc(contents) : undefined;

    const document: BaseDoc & { data: Record<string, unknown> } = {
      ...meta,

      slug: (frontmatter.slug as string) ?? meta._info.flattenedPath,
      tableOfContents: toc,

      data,
    };

    // validate the document then add it to the list
    if (validate) await validate(document);
    docs.push(document);

    // write mjs file
    const outputFilePath = path.join(outputFolder, type, `${idToFileName(document._id)}.mjs`);
    fs.writeFileSync(outputFilePath, convertDocumentToMjsContent(document), { encoding: 'utf8' });

    // update the cache
    cache.items[file] = { hash, type, document, elapsed };
    generated++;
  }

  // ensure that all documents have a unique slug
  const slugs = docs.map((doc) => doc.slug);
  const uniqueSlugs = new Set(slugs);
  if (slugs.length !== uniqueSlugs.size) {
    const duplicateSlugs = slugs.filter((slug, index) => slugs.indexOf(slug) !== index);
    const documentsWithDuplicateSlugs = docs.filter((doc) => duplicateSlugs.includes(doc.slug)).map((doc) => doc._id);
    throw new MarkdownlayerError({
      ...MarkdownlayerErrorData.DuplicateDocumentSlugError,
      message: MarkdownlayerErrorData.DuplicateDocumentSlugError.message({
        definition: type,
        slugs: duplicateSlugs,
        documents: documentsWithDuplicateSlugs,
      }),
      hint: `Remove slug from the frontmatter of the documents and ensure only one file per extension/format.`,
    });
  }

  // write the collection files if there are collection changes (or if there are no documents, to allow imports)
  if (collectionChanged || docs.length == 0) {
    // write import file
    const dataVariableName = getDataVariableName(type);
    const outputFilePath = path.join(outputFolder, type, 'index.mjs');
    const lines: string[] = [
      autogeneratedNote,
      '',
      ...docs.map((doc) => `import ${makeVariableName(doc._id)} from './${idToFileName(doc._id)}.mjs';`),
      '',
      `export const ${dataVariableName} = [${docs.map((doc) => `${makeVariableName(doc._id)}`).join(', ')}]`,
      '',
    ];
    fs.writeFileSync(outputFilePath, lines.join('\n'), { encoding: 'utf8' });
  }

  return { schema, counts: { cached, generated, total: docs.length } };
}

type WritePackageJsonFileOptions = { outputFolder: string; configHash: string };

async function writePackageJson({ outputFolder, configHash }: WritePackageJsonFileOptions) {
  const packageJson: PackageJson & { typesVersions: Record<string, unknown> } = {
    name: 'dot-markdownlayer',
    description: 'This package is auto-generated by markdownlayer.',
    version: `${version}-${configHash}`,
    private: true,
    exports: {
      './generated': {
        import: './generated/index.mjs',
      },
    },
    typesVersions: {
      '*': {
        generated: ['./generated'],
      },
    },
  };

  const filePath = path.join(outputFolder, 'package.json');
  fs.writeFileSync(filePath, JSON.stringify(packageJson, null, 2), { encoding: 'utf8' });
}

type WriteRootIndexFilesOptions = { outputFolder: string; generations: Record<string, GenerationResult> };
async function writeRootIndexFiles({ outputFolder, generations }: WriteRootIndexFilesOptions) {
  const documentTypeNames = Object.keys(generations);

  // write the index.d.ts file
  let lines: string[] = [
    autogeneratedNote,
    '',
    `import type { ImageData, BaseDoc } from 'markdownlayer/core';`,
    '',
    `export type { ImageData };`,
    '',
    ...Object.entries(generations).map(([type, { schema }]) => {
      const converted = (schema ? printNode(zodToTs(schema).node) : undefined)?.replace(';\n}', ';\n\t}');
      return `export type ${type} = BaseDoc & {\n\ttype: '${type}';\n\tdata: ${converted ?? 'any'};\n};\n`;
    }),
    '',
    `export type DocumentTypes = ${documentTypeNames.join(` | `)}`,
    `export type DocumentTypeNames = '${documentTypeNames.join(`' | '`)}'`,
    '',
    '',
    ...documentTypeNames.map((type) => `export declare const ${getDataVariableName(type)}: ${type}[];`),
    '',
    `export declare const allDocumentTypes: DocumentTypes[]`,
    '',
  ];
  let filePath = path.join(outputFolder, 'index.d.ts');
  fs.writeFileSync(filePath, lines.join('\n'), { encoding: 'utf8' });

  // write the index.mjs file
  lines = [
    autogeneratedNote,
    '',
    ...documentTypeNames.map((type) => `import { ${getDataVariableName(type)} } from './${type}/index.mjs';`),
    '',
    `export { ${documentTypeNames.map((type) => getDataVariableName(type)).join(', ')} };`,
    '',
    `export const allDocuments = [...${documentTypeNames.map((type) => getDataVariableName(type)).join(', ...')}];`,
    '',
  ];
  filePath = path.join(outputFolder, 'index.mjs');
  fs.writeFileSync(filePath, lines.join('\n'), { encoding: 'utf8' });
}

/**
 * Get flattened path from relative file path.
 * @param relativeFilePath
 * @returns string Flattened path.
 */
function getFlattenedPath(relativeFilePath: string): string {
  return (
    relativeFilePath
      // remove extension
      .split('.')
      .slice(0, -1)
      .join('.')
      // deal with root `index` file
      .replace(/^index$/, '')
      // remove tailing `/index`
      .replace(/\/index$/, '')
  );
}

// For some reason, generating toc using mdast-util-toc or even using docusaurus' own toc plugin generates entries from frontmatter.
// Most of the time it is the first entry but sometimes it is not. Removing it results in missing TOC at times.
// So we have to do it manually using regex. Hopefully this is a temporary solution and someone will fix this someday.
// Regex solution from https://yusuf.fyi/posts/contentlayer-table-of-contents

const slugger = new GithubSlugger();
const regXHeader = /\n(?<flag>#{1,6})\s+(?<content>.+)/g;

export function generateToc(contents: string): TocItem[] {
  return Array.from(contents.matchAll(regXHeader)).map(({ groups }) => {
    const { flag, content } = groups!;
    const id = slugger.slug(content);
    return {
      level: flag.length,
      value: content,
      id: id,
      url: `#${id}`,
    };
  });
}

export function convertDocumentToMjsContent(obj: unknown): string {
  function serialize(obj: unknown): string {
    if (Array.isArray(obj)) {
      const elements = obj.map((el) => serialize(el)).join(', ');
      return `[${elements}]`;
    } else if (obj instanceof Date) {
      return `new Date('${obj.toISOString()}')`;
    } else if (typeof obj === 'string') {
      // use JSON.stringify to escape special characters in strings
      return `${JSON.stringify(obj)}`;
    } else if (typeof obj === 'object' && obj !== null) {
      const props = Object.entries(obj).map(([key, value]) => `${key}: ${serialize(value)}`);
      return `{ ${props.join(', ')} }`;
    } else {
      return obj?.toString() ?? 'null';
    }
  }

  const code = [autogeneratedNote, '', `export default ${serialize(obj)}`].join('\n');
  return beautify.js(code, { indent_size: 2 });
}

const makeVariableName = (id: string) => camelCase(idToFileName(id).replace(/[^A-Z0-9_]/gi, '/0'));
const getDataVariableName = (type: string): string => 'all' + uppercaseFirstChar(pluralize(type));
const idToFileName = (id: string): string => leftPadWithUnderscoreIfStartsWithNumber(id).replace(/\//g, '__');
const leftPadWithUnderscoreIfStartsWithNumber = (str: string): string => (/^[0-9]/.test(str) ? '_' + str : str);
const uppercaseFirstChar = (str: string) => str.charAt(0).toUpperCase() + str.slice(1);
